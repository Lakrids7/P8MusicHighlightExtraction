import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import argparse
import os


def analyze_csv(csv_filepath, output_dir):
    """
    Analyzes the summary CSV file to report MAE and generate plots.
    """
    if not os.path.exists(csv_filepath):
        print(f"Error: CSV file not found at {csv_filepath}")
        return

    try:
        df = pd.read_csv(csv_filepath)
    except Exception as e:
        print(f"Error reading CSV file: {e}")
        return

    required_cols = ['error_attn_center_vs_gt_center_s', 'attn_highlight_center_s', 'gt_center_s']
    for col in required_cols:
        if col not in df.columns:
            print(f"Error: Column '{col}' not found in the CSV.")
            print("Make sure you are using the CSV generated by the modified analysis script.")
            return

    # --- Create output directory ---
    os.makedirs(output_dir, exist_ok=True)
    print(f"Plots will be saved to: {output_dir}")

    # --- Data Cleaning and Preparation ---
    df['error_attn_center_vs_gt_center_s'] = pd.to_numeric(df['error_attn_center_vs_gt_center_s'], errors='coerce')
    valid_errors = df['error_attn_center_vs_gt_center_s'].dropna()

    df['attn_highlight_center_s'] = pd.to_numeric(df['attn_highlight_center_s'], errors='coerce')
    valid_pred_centers = df['attn_highlight_center_s'].dropna()

    df['gt_center_s'] = pd.to_numeric(df['gt_center_s'], errors='coerce')
    valid_gt_centers = df['gt_center_s'].dropna()

    if valid_errors.empty:
        print("No valid error data found to analyze.")
    else:
        num_songs_analyzed_errors = len(valid_errors)
        print(f"\n--- Analysis of Attention-Derived Highlight Center Error ({num_songs_analyzed_errors} songs) ---")
        mae = valid_errors.abs().mean()
        median_error = valid_errors.abs().median()
        std_dev_error = valid_errors.abs().std()
        min_error = valid_errors.abs().min()
        max_error = valid_errors.abs().max()

        print(f"Mean Absolute Error (MAE): {mae:.2f} seconds")
        print(f"Median Absolute Error:     {median_error:.2f} seconds")
        print(f"Standard Deviation of AE:  {std_dev_error:.2f} seconds")
        print(f"Min Absolute Error:        {min_error:.2f} seconds")
        print(f"Max Absolute Error:        {max_error:.2f} seconds")

    # --- Generate Plots ---

    # 1. Histogram of Errors (if data exists)
    if not valid_errors.empty:
        plt.figure(figsize=(10, 6))
        sns.histplot(valid_errors.abs(), kde=True, bins=30)
        plt.title(
            f'Distribution of Absolute Center Errors (Attention-Derived Highlight)\nMAE: {mae:.2f}s, Median AE: {median_error:.2f}s')
        plt.xlabel('Absolute Error in Highlight Center (seconds)')
        plt.ylabel('Number of Songs')
        plt.grid(True, linestyle=':', alpha=0.7)
        plt.tight_layout()
        hist_path = os.path.join(output_dir, "histogram_center_errors.png")
        plt.savefig(hist_path)
        plt.close()
        print(f"Saved histogram of errors to: {hist_path}")
    else:
        print("Skipping histogram of errors due to no valid error data.")

    # 2. Cumulative Distribution Function (CDF) of Errors (if data exists)
    if not valid_errors.empty:
        sorted_errors = np.sort(valid_errors.abs())
        y_cdf = np.arange(1, len(sorted_errors) + 1) / len(sorted_errors)
        plt.figure(figsize=(10, 6))
        plt.plot(sorted_errors, y_cdf, marker='.', linestyle='none')
        plt.plot(sorted_errors, y_cdf)  # Add line for better visibility
        plt.title('CDF of Absolute Center Errors (Attention-Derived Highlight)')
        plt.xlabel('Absolute Error in Highlight Center (seconds)')
        plt.ylabel('Cumulative Probability (Proportion of Songs)')
        plt.yticks(np.arange(0, 1.1, 0.1))
        plt.grid(True, linestyle=':', alpha=0.7)
        for percentile in [0.5, 0.75, 0.9, 0.95]:
            error_at_percentile = np.percentile(sorted_errors, percentile * 100)
            plt.axhline(y=percentile, color='r', linestyle='--', alpha=0.5,
                        label=f'{int(percentile * 100)}th percentile ({error_at_percentile:.2f}s)')
            plt.axvline(x=error_at_percentile, color='r', linestyle='--', alpha=0.5)
        plt.legend()
        plt.tight_layout()
        cdf_path = os.path.join(output_dir, "cdf_center_errors.png")
        plt.savefig(cdf_path)
        plt.close()
        print(f"Saved CDF of errors to: {cdf_path}")
    else:
        print("Skipping CDF of errors due to no valid error data.")

    # 3. Scatter Plot: Attention Sum in GT vs. Attention Sum in Attn Highlight (if data exists)
    if 'sum_attn_in_gt_window' in df.columns and 'sum_attn_in_attn_highlight_window' in df.columns:
        df['sum_attn_in_gt_window'] = pd.to_numeric(df['sum_attn_in_gt_window'], errors='coerce')
        df['sum_attn_in_attn_highlight_window'] = pd.to_numeric(df['sum_attn_in_attn_highlight_window'],
                                                                errors='coerce')

        valid_attn_sums_df = df[['sum_attn_in_gt_window', 'sum_attn_in_attn_highlight_window']].dropna()

        if not valid_attn_sums_df.empty:
            plt.figure(figsize=(8, 8))
            sns.scatterplot(x='sum_attn_in_gt_window', y='sum_attn_in_attn_highlight_window', data=valid_attn_sums_df,
                            alpha=0.6)
            min_val = min(valid_attn_sums_df['sum_attn_in_gt_window'].min(),
                          valid_attn_sums_df['sum_attn_in_attn_highlight_window'].min())
            max_val = max(valid_attn_sums_df['sum_attn_in_gt_window'].max(),
                          valid_attn_sums_df['sum_attn_in_attn_highlight_window'].max())
            if pd.notna(min_val) and pd.notna(max_val):
                plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', label='Identity (y=x)')
            plt.title('Attention Sum Comparison')
            plt.xlabel('Sum of Attention Scores in Ground Truth Window')
            plt.ylabel('Sum of Attention Scores in Attention-Derived Highlight Window')
            plt.legend()
            plt.grid(True, linestyle=':', alpha=0.7)
            plt.axis('equal')
            plt.tight_layout()
            attn_scatter_path = os.path.join(output_dir, "scatter_attention_sums.png")
            plt.savefig(attn_scatter_path)
            plt.close()
            print(f"Saved scatter plot of attention sums to: {attn_scatter_path}")
        else:
            print("Could not generate attention sum scatter plot due to missing or invalid data.")
    else:
        print("Columns for attention sums not found; skipping scatter plot.")

    # 4. Distribution of Predicted vs. Ground Truth Highlight Centers (USING HISTOGRAMS)
    if not valid_pred_centers.empty or not valid_gt_centers.empty:
        plt.figure(figsize=(12, 7))

        # Determine common bins for both histograms to ensure comparability
        # Find overall min and max to set a common range for bins
        all_centers = []
        if not valid_pred_centers.empty: all_centers.extend(valid_pred_centers.tolist())
        if not valid_gt_centers.empty: all_centers.extend(valid_gt_centers.tolist())

        if all_centers:
            bin_edges = np.histogram_bin_edges(all_centers, bins=50)  # Or 'auto', or a fixed number

            if not valid_pred_centers.empty:
                sns.histplot(valid_pred_centers, bins=bin_edges, label='Predicted (Attention-Derived) Centers',
                             alpha=0.7, color='skyblue', element="step", linewidth=1.5,
                             stat="count")  # Use step for outline
                sns.histplot(valid_pred_centers, bins=bin_edges, alpha=0.3, color='skyblue',
                             stat="count")  # Add light fill

            if not valid_gt_centers.empty:
                sns.histplot(valid_gt_centers, bins=bin_edges, label='Ground Truth Centers',
                             alpha=0.7, color='salmon', element="step", linewidth=1.5, stat="count")
                sns.histplot(valid_gt_centers, bins=bin_edges, alpha=0.3, color='salmon', stat="count")

        plt.title(f'Distribution of Predicted vs. Ground Truth Highlight Centers')
        plt.xlabel('Highlight Center Timestamp (seconds)')
        plt.ylabel('Number of Songs (Count)')  # Changed y-axis label
        plt.legend()
        plt.grid(True, linestyle=':', alpha=0.7)
        plt.tight_layout()
        pred_gt_centers_hist_path = os.path.join(output_dir,
                                                 "histogram_predicted_vs_gt_highlight_centers.png")  # Filename changed
        plt.savefig(pred_gt_centers_hist_path)
        plt.close()
        print(f"Saved histogram plot of predicted vs. GT highlight centers to: {pred_gt_centers_hist_path}")

        if not valid_pred_centers.empty:
            print(f"\n--- Statistics for Predicted Attention Highlight Centers ({len(valid_pred_centers)} songs) ---")
            print(f"Mean Predicted Center:   {valid_pred_centers.mean():.2f} seconds")
            print(f"Median Predicted Center: {valid_pred_centers.median():.2f} seconds")
            # ... (rest of stats remain the same)
            print(f"Std Dev Predicted Center:{valid_pred_centers.std():.2f} seconds")
            print(f"Min Predicted Center:    {valid_pred_centers.min():.2f} seconds")
            print(f"Max Predicted Center:    {valid_pred_centers.max():.2f} seconds")

        if not valid_gt_centers.empty:
            print(f"\n--- Statistics for Ground Truth Highlight Centers ({len(valid_gt_centers)} songs) ---")
            print(f"Mean GT Center:   {valid_gt_centers.mean():.2f} seconds")
            print(f"Median GT Center: {valid_gt_centers.median():.2f} seconds")
            # ... (rest of stats remain the same)
            print(f"Std Dev GT Center:{valid_gt_centers.std():.2f} seconds")
            print(f"Min GT Center:    {valid_gt_centers.min():.2f} seconds")
            print(f"Max GT Center:    {valid_gt_centers.max():.2f} seconds")

    else:
        print("No valid predicted or ground truth highlight center data found to plot their distribution.")

    print("\nCSV analysis complete.")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Analyze the summary CSV from the attention-based highlight evaluation.")
    parser.add_argument("--csv_file", type=str, required=True,
                        help="Path to the 'analysis_summary_all_processed_songs.csv' file.")
    parser.add_argument("--output_dir", type=str, default="csv_analysis_plots",
                        help="Directory to save the generated plots.")
    args = parser.parse_args()

    analyze_csv(args.csv_file, args.output_dir)